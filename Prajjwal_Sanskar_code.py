# -*- coding: utf-8 -*-
"""parth_gupta_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ML5XnnCe3RP0A11oX6X_OS1LGhPerqRr
"""

#@title Uploading the three files
from google.colab import files
uploaded = files.upload()

#@title Joining both dataframes
import pandas as pd
trn = pd.read_csv('glitch_trn_data.csv')
label=pd.read_csv('glitch_trn_class_labels.csv',names=["D_value","Type"])

dataset=pd.concat([trn,label],axis=1)
dataset=dataset.dropna().drop("D_value",axis=1).drop("id",axis=1)

import warnings
warnings.filterwarnings('ignore')

#@title Visualisation

h1df=pd.DataFrame(columns=dataset.columns)
l1df=pd.DataFrame(columns=dataset.columns)
for row in dataset.values:
  #print(row)
  if row[4] == "H1":
    h1df.loc[len(h1df)]=row
  elif row[4] == "L1":
    l1df.loc[len(l1df)]=row
tmpstr="1080Lines,1400Ripples,Air_Compressor,Blip,Chirp,Extremely_Loud,Helix,Koi_Fish,Light_Modulation,Low_Frequency_Burst,Low_Frequency_Lines,No_Glitch,None_of_the_Above,Paired_Doves,Power_Line,Repeating_Blips,Scattered_Light,Scratchy,Tomte,Violin_Mode,Wandering_Line,Whistle"
array_all_glitch_types=tmpstr.split(",")
array_occurences_df=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
array_occurences_h1df=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
array_occurences_l1df=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
for row in dataset.values:
  index=array_all_glitch_types.index(row[-1])
  array_occurences_df[index]= array_occurences_df[index]+1

for row in h1df.values:
  index=array_all_glitch_types.index(row[-1])
  array_occurences_h1df[index]= array_occurences_h1df[index]+1

for row in l1df.values:
  index=array_all_glitch_types.index(row[-1])
  array_occurences_l1df[index]= array_occurences_l1df[index]+1

#@title class distribution for overall dataset
from matplotlib import pyplot as plt

# Set the figure size
plt.rcParams["figure.figsize"] = [7.00, 7.00]
plt.rcParams["figure.autolayout"] = True
plt.title("class distribution for overall dataset")
# List of data points
#data = [0, 1, 3, 2, 1, 5, 2, 1, 4, 2, 4, 0]

# Plot bar chart with data points
plt.bar(array_all_glitch_types, array_occurences_df)

plt.xticks(rotation=90)
# Display the plot
plt.show()

#@title class distribution for H1 dataset
from matplotlib import pyplot as plt

# Set the figure size
plt.rcParams["figure.figsize"] = [7.00, 7.00]
plt.rcParams["figure.autolayout"] = True
plt.title("class distribution for H1 dataset")
# List of data points
#data = [0, 1, 3, 2, 1, 5, 2, 1, 4, 2, 4, 0]

# Plot bar chart with data points
plt.bar(array_all_glitch_types, array_occurences_h1df)

plt.xticks(rotation=90)
# Display the plot
plt.show()

#@title class distribution for L1 dataset
from matplotlib import pyplot as plt

# Set the figure size
plt.rcParams["figure.figsize"] = [7.00, 7.00]
plt.rcParams["figure.autolayout"] = True
plt.title("class distribution for L1 dataset")
# List of data points
#data = [0, 1, 3, 2, 1, 5, 2, 1, 4, 2, 4, 0]

# Plot bar chart with data points
plt.bar(array_all_glitch_types, array_occurences_l1df)

plt.xticks(rotation=90)
# Display the plot
plt.show()

"""Without Normalisation and without taking ifo into account"""

#@title check scores after running gridsearch
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import precision_recall_fscore_support
from sklearn import linear_model
from sklearn.model_selection import GridSearchCV
from sklearn import svm

df1=dataset.drop("ifo",axis=1)

X = df1.drop("Type",axis=1)
y = df1["Type"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)

models = [
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    KNeighborsClassifier(),
    linear_model.LogisticRegression(multi_class='multinomial')
]
for model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    precision, recall, f_measure, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')
    print(f'Before gridsearch, Model: {type(model).__name__} | Precision: {precision} | Recall: {recall} | F-measure: {f_measure}')

    scoring = ['precision_macro', 'recall_macro', 'f1_macro']
    param_grid = {}
    if type(model).__name__ == 'DecisionTreeClassifier':
        param_grid = {
            'criterion': ['gini', 'entropy'],
            'max_depth': [5, 10, 20, None],
            'min_samples_split': [2, 5, 10]
        }
    elif type(model).__name__ == 'RandomForestClassifier':
        param_grid = {
            'n_estimators': [10, 50, 100],
            'criterion': ['gini', 'entropy'],
            'max_depth': [5, 10, 20, None],
            'min_samples_split': [2, 5, 10]
        }
    elif type(model).__name__ == 'LogisticRegression':
        param_grid = {
            'C': [1, 10, 100],
            'penalty': ['l2'],
            'solver': ['lbfgs', 'newton-cg'],
            'max_iter': [100, 500, 1000]
        }
    elif type(model).__name__ == 'KNeighborsClassifier':
        param_grid = {
            'n_neighbors': [3, 5, 7, 10],
            'weights': ['uniform', 'distance'],
            'metric': ['euclidean', 'manhattan']
        }
    
    grid_search = GridSearchCV(model, param_grid, cv=4,verbose=1,n_jobs=-1,scoring=scoring, refit='f1_macro')
    grid_search.fit(X_train, y_train)
    print(f"Best hyperparameters for {type(model).__name__}: {grid_search.best_params_}")
    
    model = grid_search.best_estimator_
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    precision, recall, f_measure, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')
    print(f'After gridsearch Model: {type(model).__name__} | Precision: {precision} | Recall: {recall} | F-measure: {f_measure}\n')

"""from sklearn import svm
model_svm=svm.SVC(C=1000,kernel='linear',random_state=10)

model_svm.fit(X_train,y_train)

y_pred= model_svm.predict(X_test)
y_pred

Without normalisation but taking ifo into account
"""

pip install category_encoders

#@title onehot encoding
import category_encoders as ce
encoder=ce.OneHotEncoder(cols='ifo',use_cat_names=True)
df2=dataset
df2encoded=encoder.fit_transform(df2)

#@title check scores after running gridsearch
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import precision_recall_fscore_support
from sklearn import linear_model
from sklearn.model_selection import GridSearchCV

X = df2encoded.drop("Type",axis=1)
y = df2encoded["Type"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)

models = [
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    KNeighborsClassifier(),
    linear_model.LogisticRegression(multi_class='multinomial')
]
for model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    precision, recall, f_measure, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')
    print(f'Before Gridsearch Model: {type(model).__name__} | Precision: {precision} | Recall: {recall} | F-measure: {f_measure}')

    scoring = ['precision_macro', 'recall_macro', 'f1_macro']
    param_grid = {}
    if type(model).__name__ == 'DecisionTreeClassifier':
        param_grid = {
            'criterion': ['gini', 'entropy'],
            'max_depth': [5, 10, 20, None],
            'min_samples_split': [2, 5, 10]
        }
    elif type(model).__name__ == 'RandomForestClassifier':
        param_grid = {
            'n_estimators': [10, 50, 100],
            'criterion': ['gini', 'entropy'],
            'max_depth': [5, 10, 20, None],
            'min_samples_split': [2, 5, 10]
        }
    elif type(model).__name__ == 'LogisticRegression':
        param_grid = {
            'C': [1, 10, 100],
            'penalty': ['l2'],
            'solver': ['lbfgs', 'newton-cg'],
            'max_iter': [100, 500, 1000]
        }
    elif type(model).__name__ == 'KNeighborsClassifier':
        param_grid = {
            'n_neighbors': [3, 5, 7, 10],
            'weights': ['uniform', 'distance'],
            'metric': ['euclidean', 'manhattan']
        }
    
    grid_search = GridSearchCV(model, param_grid, cv=4,verbose=1,n_jobs=-1,scoring=scoring, refit='f1_macro')
    grid_search.fit(X_train, y_train)
    print(f"Best hyperparameters for {type(model).__name__}: {grid_search.best_params_}")
    model = grid_search.best_estimator_
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    precision, recall, f_measure, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')
    print(f'After Griddsearch Model: {type(model).__name__} | Precision: {precision} | Recall: {recall} | F-measure: {f_measure}\n')

"""With Normalisation and without taking ifo into account"""

#@title normalization routine
train_stats= dataset.describe()
train_stats=train_stats.transpose()
train_stats

def norm(x):
  return (x-train_stats['mean'])/train_stats['std']

df3=dataset.drop("ifo",axis=1)
df3normed=norm(df3.drop("Type",axis=1))
df3normed["Type"]=dataset["Type"]
print(df3normed)

#@title check scores after gridsearch
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import precision_recall_fscore_support
from sklearn import linear_model
from sklearn.model_selection import GridSearchCV

X = df3normed.drop("Type",axis=1)
y = df3normed["Type"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)

models = [
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    KNeighborsClassifier(),
    linear_model.LogisticRegression(multi_class='multinomial')
]
for model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    precision, recall, f_measure, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')
    print(f'Before gridsearch Model: {type(model).__name__} | Precision: {precision} | Recall: {recall} | F-measure: {f_measure}')

    scoring = ['precision_macro', 'recall_macro', 'f1_macro']
    param_grid = {}
    if type(model).__name__ == 'DecisionTreeClassifier':
        param_grid = {
            'criterion': ['gini', 'entropy'],
            'max_depth': [5, 10, 20, None],
            'min_samples_split': [2, 5, 10]
        }
    elif type(model).__name__ == 'RandomForestClassifier':
        param_grid = {
            'n_estimators': [10, 50, 100],
            'criterion': ['gini', 'entropy'],
            'max_depth': [5, 10, 20, None],
            'min_samples_split': [2, 5, 10]
        }
    elif type(model).__name__ == 'LogisticRegression':
        param_grid = {
            'C': [1, 10, 100],
            'penalty': ['l2'],
            'solver': ['lbfgs', 'newton-cg'],
            'max_iter': [100, 500, 1000]
        }
    elif type(model).__name__ == 'KNeighborsClassifier':
        param_grid = {
            'n_neighbors': [3, 5, 7, 10],
            'weights': ['uniform', 'distance'],
            'metric': ['euclidean', 'manhattan']
        }
    
    grid_search = GridSearchCV(model, param_grid, cv=4,verbose=1,n_jobs=-1,scoring=scoring, refit='f1_macro')
    grid_search.fit(X_train, y_train)
    print(f"Best hyperparameters for {type(model).__name__}: {grid_search.best_params_}")
    model = grid_search.best_estimator_
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    precision, recall, f_measure, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')
    print(f'After gridsearch Model: {type(model).__name__} | Precision: {precision} | Recall: {recall} | F-measure: {f_measure}\n')

"""with normalization but taking ifo into account"""

#@title normalization routine
import category_encoders as ce
encoder=ce.OneHotEncoder(cols='ifo',use_cat_names=True)
df4=dataset
df4encoded=encoder.fit_transform(df4)

train_stats= df4encoded.describe()
train_stats=train_stats.transpose()
train_stats


def norm(x):
  return (x-train_stats['mean'])/train_stats['std']

df4normed=norm(df4encoded.drop("Type",axis=1))
df4normed["Type"]=dataset["Type"]

#@title check scores after gridsearch
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import precision_recall_fscore_support
from sklearn import linear_model
from sklearn.model_selection import GridSearchCV

X = df4normed.drop("Type",axis=1)
y = df4normed["Type"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)

models = [
    DecisionTreeClassifier(),
    RandomForestClassifier(),
    KNeighborsClassifier(),
    linear_model.LogisticRegression(multi_class='multinomial')
]
for model in models:
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    precision, recall, f_measure, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')
    print(f'Before Gridsearch Model: {type(model).__name__} | Precision: {precision} | Recall: {recall} | F-measure: {f_measure}')

    scoring = ['precision_macro', 'recall_macro', 'f1_macro']
    param_grid = {}
    if type(model).__name__ == 'DecisionTreeClassifier':
        param_grid = {
            'criterion': ['gini', 'entropy'],
            'max_depth': [5, 10, 20, None],
            'min_samples_split': [2, 5, 10]
        }
    elif type(model).__name__ == 'RandomForestClassifier':
        param_grid = {
            'n_estimators': [10, 50, 100],
            'criterion': ['gini', 'entropy'],
            'max_depth': [5, 10, 20, None],
            'min_samples_split': [2, 5, 10]
        }
    elif type(model).__name__ == 'LogisticRegression':
        param_grid = {
            'C': [1, 10, 100],
            'penalty': ['l2'],
            'solver': ['lbfgs', 'newton-cg'],
            'max_iter': [100, 500, 1000]
        }
    elif type(model).__name__ == 'KNeighborsClassifier':
        param_grid = {
            'n_neighbors': [3, 5, 7, 10],
            'weights': ['uniform', 'distance'],
            'metric': ['euclidean', 'manhattan']
        }
    
    grid_search = GridSearchCV(model, param_grid, cv=4,verbose=1,n_jobs=-1,scoring=scoring, refit='f1_macro')
    grid_search.fit(X_train, y_train)
    print(f"Best hyperparameters for {type(model).__name__}: {grid_search.best_params_}")
    model = grid_search.best_estimator_
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    precision, recall, f_measure, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')
    print(f'After gridsearch Model: {type(model).__name__} | Precision: {precision} | Recall: {recall} | F-measure: {f_measure}\n')

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
df7=dataset.drop("ifo",axis=1)
X=df7.drop("Type",axis=1)
y=df7["Type"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, stratify=y)

dt=DecisionTreeClassifier(criterion='entropy', max_depth=None, min_samples_split=2)
dt.fit(X_train, y_train)
tstdata=pd.read_csv('glitch_tst_data.csv')
test_ids = tstdata['id']
x_test_unknown=tstdata.drop("id",axis=1).drop("ifo",axis=1)

predictions=dt.predict(x_test_unknown)
results_df = pd.DataFrame({'id': test_ids, 'predicted_class': predictions})

print(results_df)
results_df.to_csv('my_dataframe.csv', index=True)

from google.colab import files
files.download('my_dataframe.csv')